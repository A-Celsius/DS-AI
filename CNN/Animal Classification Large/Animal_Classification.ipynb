{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "HShbVzXytQPS"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/animals"
      ],
      "metadata": {
        "id": "ONGHUoNO0jeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7873c2e5-8725-40a3-8963-bf2326653bc5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/animals\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categories = ['antelope','badger','bat','bear','bee','beetle','bison','boar','butterfly','cat','caterpillar','chimpanzee','cockroach','cow','coyote','crab',\n",
        "              'crow','deer','dog','dolphin','donkey','dragonfly','duck','eagle','elephant','flamingo','fly','fox','goat','goldfish','goose','gorilla',\n",
        "              'grasshopper','hamster','hare','hedgehog','hippopotamus','hornbill','horse','hummingbird','hyena','jellyfish','kangaroo','koala','ladybugs',\n",
        "              'leopard','lion','lizard','lobster','mosquito','moth','mouse','octopus','okapi','orangutan','otter','owl','ox','oyster','panda','parrot',\n",
        "              'pelecaniformes','penguin','pig','pigeon','porcupine','possum','raccoon','rat','reindeer','rhinoceros','sandpiper','seahorse','seal','shark',\n",
        "              'sheep','snake','sparrow','squid','squirrel','starfish','swan','tiger','turkey','turtle','whale','wolf','wombat','woodpecker','zebra']\n"
      ],
      "metadata": {
        "id": "6_1s5P4dNh66"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code for making images into array\n",
        "i = 0\n",
        "data=[]\n",
        "labels=[]\n",
        "for label, category in enumerate(categories):\n",
        "    for file in os.listdir(category):\n",
        "        i += 1\n",
        "        img = cv2.imread(os.path.join(category, file))\n",
        "        img = cv2.resize(img, (50, 50))\n",
        "        print(i)\n",
        "        clear_output()\n",
        "        print(i)\n",
        "        data.append(img)\n",
        "        labels.append(label)"
      ],
      "metadata": {
        "id": "OCrQv4zbvYR6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "107676c9-01a8-44ed-d52b-5b83855a657a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Since the \"data\" and \"labels\" are normal array , convert them to numpy arrays-\n",
        "\n",
        "animals=np.array(data)\n",
        "labels=np.array(labels)"
      ],
      "metadata": {
        "id": "x8U9jCBSvbI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now save these numpy arrays so that you dont need to do this image manipulation again.\n",
        "\n",
        "np.save(\"animals\",animals)\n",
        "np.save(\"labels\",labels)"
      ],
      "metadata": {
        "id": "D8wkLQawv9nG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the arrays ( Optional : Required only if you have closed your jupyter notebook after saving numpy array )\n",
        "\n",
        "animals=np.load(\"animals.npy\")\n",
        "labels=np.load(\"labels.npy\")"
      ],
      "metadata": {
        "id": "X--txtW_wSJh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now shuffle the \"animals\" and \"labels\" set so that we get good mixture when we separate the dataset into train and test\n",
        "\n",
        "s=np.arange(animals.shape[0])\n",
        "np.random.shuffle(s)\n",
        "animals=animals[s]\n",
        "labels=labels[s]"
      ],
      "metadata": {
        "id": "sIVENiefwYXt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a variable num_classes which is the total number of animal categories and a variable data_length which is size of dataset\n",
        "\n",
        "num_classes=len(np.unique(labels))\n",
        "data_length=len(animals)"
      ],
      "metadata": {
        "id": "kBY_33YtweZe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Divide data into test and train\n",
        "\n",
        "# Take 90% of data in train set and 10% in test set\n",
        "\n",
        "(x_train,x_test)=animals[(int)(0.1*data_length):],animals[:(int)(0.1*data_length)]\n",
        "x_train = x_train.astype('float32')/255\n",
        "x_test = x_test.astype('float32')/255\n",
        "train_length=len(x_train)\n",
        "test_length=len(x_test)"
      ],
      "metadata": {
        "id": "dUmcBAouwgkd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Divide labels into test and train\n",
        "\n",
        "(y_train,y_test)=labels[(int)(0.1*data_length):],labels[:(int)(0.1*data_length)]"
      ],
      "metadata": {
        "id": "aBu6VALpwsM0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make labels into One Hot Encoding\n",
        "\n",
        "import keras\n",
        "#One hot encoding\n",
        "y_train=keras.utils.to_categorical(y_train,num_classes)\n",
        "y_test=keras.utils.to_categorical(y_test,num_classes)"
      ],
      "metadata": {
        "id": "Z_no2L_6wx0W"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making Keras Model\n",
        "\n",
        "# import sequential model and all the required layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout, BatchNormalization\n",
        "from keras.models import Sequential\n"
      ],
      "metadata": {
        "id": "Midz-tPPw3Xv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#make model\n",
        "cnn4 = Sequential()\n",
        "cnn4.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(50,50,3)))\n",
        "cnn4.add(BatchNormalization())\n",
        "\n",
        "cnn4.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
        "cnn4.add(BatchNormalization())\n",
        "cnn4.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "cnn4.add(Dropout(0.25))\n",
        "\n",
        "cnn4.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "cnn4.add(BatchNormalization())\n",
        "cnn4.add(Dropout(0.25))\n",
        "\n",
        "cnn4.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "\n",
        "cnn4.add(BatchNormalization())\n",
        "cnn4.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "cnn4.add(Dropout(0.25))\n",
        "\n",
        "cnn4.add(Flatten())\n",
        "\n",
        "cnn4.add(Dense(512, activation='relu'))\n",
        "cnn4.add(BatchNormalization())\n",
        "cnn4.add(Dropout(0.5))\n",
        "\n",
        "cnn4.add(Dense(128, activation='relu'))\n",
        "cnn4.add(BatchNormalization())\n",
        "cnn4.add(Dropout(0.5))\n",
        "\n",
        "cnn4.add(Dense(90, activation='softmax'))\n",
        "\n"
      ],
      "metadata": {
        "id": "ETu-eD9Nw6wR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn4.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXq1IHYtBKHa",
        "outputId": "19d53f44-621b-4982-85a2-cbf6832bc1b1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 48, 48, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 48, 48, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 46, 46, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 46, 46, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 23, 23, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 23, 23, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 21, 21, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 21, 21, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 21, 21, 64)        0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 19, 19, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 19, 19, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 9, 9, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 9, 9, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 10368)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               5308928   \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               65664     \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 90)                11610     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,492,282\n",
            "Trainable params: 5,490,490\n",
            "Non-trainable params: 1,792\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the model\n",
        "cnn4.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Xp9v4ogqw9C_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "cnn4.fit(x_train,y_train,batch_size=30,epochs=100,verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqEwIlKJxAsF",
        "outputId": "315b61ef-a3c2-4e42-e1fd-fd8e190f9b27"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "162/162 [==============================] - 12s 11ms/step - loss: 4.9488 - accuracy: 0.0321\n",
            "Epoch 2/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 4.4183 - accuracy: 0.0519\n",
            "Epoch 3/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 4.1130 - accuracy: 0.0755\n",
            "Epoch 4/100\n",
            "162/162 [==============================] - 2s 12ms/step - loss: 3.8791 - accuracy: 0.1080\n",
            "Epoch 5/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 3.6740 - accuracy: 0.1368\n",
            "Epoch 6/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 3.5026 - accuracy: 0.1710\n",
            "Epoch 7/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 3.3478 - accuracy: 0.1934\n",
            "Epoch 8/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 3.2024 - accuracy: 0.2302\n",
            "Epoch 9/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 3.0485 - accuracy: 0.2597\n",
            "Epoch 10/100\n",
            "162/162 [==============================] - 2s 12ms/step - loss: 2.8903 - accuracy: 0.2794\n",
            "Epoch 11/100\n",
            "162/162 [==============================] - 2s 12ms/step - loss: 2.8125 - accuracy: 0.3060\n",
            "Epoch 12/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 2.7464 - accuracy: 0.3171\n",
            "Epoch 13/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 2.5375 - accuracy: 0.3564\n",
            "Epoch 14/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 2.4717 - accuracy: 0.3761\n",
            "Epoch 15/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 2.3326 - accuracy: 0.3947\n",
            "Epoch 16/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 2.1187 - accuracy: 0.4492\n",
            "Epoch 17/100\n",
            "162/162 [==============================] - 2s 12ms/step - loss: 2.0582 - accuracy: 0.4593\n",
            "Epoch 18/100\n",
            "162/162 [==============================] - 2s 12ms/step - loss: 1.9222 - accuracy: 0.4953\n",
            "Epoch 19/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 1.7661 - accuracy: 0.5259\n",
            "Epoch 20/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 1.6909 - accuracy: 0.5459\n",
            "Epoch 21/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 1.5294 - accuracy: 0.5872\n",
            "Epoch 22/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 1.3353 - accuracy: 0.6337\n",
            "Epoch 23/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 1.2135 - accuracy: 0.6642\n",
            "Epoch 24/100\n",
            "162/162 [==============================] - 2s 12ms/step - loss: 1.1434 - accuracy: 0.6790\n",
            "Epoch 25/100\n",
            "162/162 [==============================] - 2s 12ms/step - loss: 1.0137 - accuracy: 0.7113\n",
            "Epoch 26/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 1.0578 - accuracy: 0.7051\n",
            "Epoch 27/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 0.9540 - accuracy: 0.7263\n",
            "Epoch 28/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 0.8847 - accuracy: 0.7459\n",
            "Epoch 29/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 0.7490 - accuracy: 0.7837\n",
            "Epoch 30/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 0.7967 - accuracy: 0.7710\n",
            "Epoch 31/100\n",
            "162/162 [==============================] - 2s 12ms/step - loss: 0.7715 - accuracy: 0.7745\n",
            "Epoch 32/100\n",
            "162/162 [==============================] - 2s 12ms/step - loss: 0.6926 - accuracy: 0.7990\n",
            "Epoch 33/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 0.6315 - accuracy: 0.8126\n",
            "Epoch 34/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 0.6011 - accuracy: 0.8226\n",
            "Epoch 35/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 0.5573 - accuracy: 0.8325\n",
            "Epoch 36/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 0.5025 - accuracy: 0.8527\n",
            "Epoch 37/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 0.5550 - accuracy: 0.8348\n",
            "Epoch 38/100\n",
            "162/162 [==============================] - 2s 12ms/step - loss: 0.4822 - accuracy: 0.8556\n",
            "Epoch 39/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 0.4596 - accuracy: 0.8648\n",
            "Epoch 40/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 0.4447 - accuracy: 0.8640\n",
            "Epoch 41/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 0.4358 - accuracy: 0.8677\n",
            "Epoch 42/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 0.4376 - accuracy: 0.8669\n",
            "Epoch 43/100\n",
            "162/162 [==============================] - 2s 12ms/step - loss: 0.4042 - accuracy: 0.8815\n",
            "Epoch 44/100\n",
            "162/162 [==============================] - 2s 12ms/step - loss: 0.4014 - accuracy: 0.8765\n",
            "Epoch 45/100\n",
            "162/162 [==============================] - 2s 12ms/step - loss: 0.4445 - accuracy: 0.8691\n",
            "Epoch 46/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 0.4150 - accuracy: 0.8741\n",
            "Epoch 47/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 0.3671 - accuracy: 0.8881\n",
            "Epoch 48/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 0.3404 - accuracy: 0.8963\n",
            "Epoch 49/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 0.3372 - accuracy: 0.8967\n",
            "Epoch 50/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 0.4019 - accuracy: 0.8770\n",
            "Epoch 51/100\n",
            "162/162 [==============================] - 2s 12ms/step - loss: 0.3594 - accuracy: 0.8905\n",
            "Epoch 52/100\n",
            "162/162 [==============================] - 2s 12ms/step - loss: 0.3173 - accuracy: 0.9004\n",
            "Epoch 53/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 0.3135 - accuracy: 0.9074\n",
            "Epoch 54/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 0.2677 - accuracy: 0.9224\n",
            "Epoch 55/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 0.2654 - accuracy: 0.9193\n",
            "Epoch 56/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 0.2498 - accuracy: 0.9247\n",
            "Epoch 57/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 0.2794 - accuracy: 0.9154\n",
            "Epoch 58/100\n",
            "162/162 [==============================] - 2s 13ms/step - loss: 0.2813 - accuracy: 0.9150\n",
            "Epoch 59/100\n",
            "162/162 [==============================] - 2s 12ms/step - loss: 0.2542 - accuracy: 0.9230\n",
            "Epoch 60/100\n",
            "162/162 [==============================] - 2s 12ms/step - loss: 0.2445 - accuracy: 0.9220\n",
            "Epoch 61/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 0.3129 - accuracy: 0.9056\n",
            "Epoch 62/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 0.2669 - accuracy: 0.9171\n",
            "Epoch 63/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 0.2411 - accuracy: 0.9290\n",
            "Epoch 64/100\n",
            "162/162 [==============================] - 2s 12ms/step - loss: 0.2399 - accuracy: 0.9259\n",
            "Epoch 65/100\n",
            "162/162 [==============================] - 2s 12ms/step - loss: 0.2756 - accuracy: 0.9179\n",
            "Epoch 66/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 0.2471 - accuracy: 0.9235\n",
            "Epoch 67/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 0.1958 - accuracy: 0.9414\n",
            "Epoch 68/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 0.2303 - accuracy: 0.9311\n",
            "Epoch 69/100\n",
            "162/162 [==============================] - 2s 12ms/step - loss: 0.2250 - accuracy: 0.9327\n",
            "Epoch 70/100\n",
            "162/162 [==============================] - 2s 12ms/step - loss: 0.2210 - accuracy: 0.9294\n",
            "Epoch 71/100\n",
            "162/162 [==============================] - 2s 13ms/step - loss: 0.2661 - accuracy: 0.9195\n",
            "Epoch 72/100\n",
            "162/162 [==============================] - 2s 12ms/step - loss: 0.2088 - accuracy: 0.9350\n",
            "Epoch 73/100\n",
            "162/162 [==============================] - 2s 12ms/step - loss: 0.1864 - accuracy: 0.9407\n",
            "Epoch 74/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 0.2045 - accuracy: 0.9374\n",
            "Epoch 75/100\n",
            "162/162 [==============================] - 2s 12ms/step - loss: 0.2096 - accuracy: 0.9344\n",
            "Epoch 76/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 0.2090 - accuracy: 0.9352\n",
            "Epoch 77/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 0.1966 - accuracy: 0.9374\n",
            "Epoch 78/100\n",
            "162/162 [==============================] - 2s 12ms/step - loss: 0.2112 - accuracy: 0.9331\n",
            "Epoch 79/100\n",
            "162/162 [==============================] - 2s 12ms/step - loss: 0.1883 - accuracy: 0.9414\n",
            "Epoch 80/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 0.1894 - accuracy: 0.9409\n",
            "Epoch 81/100\n",
            "162/162 [==============================] - 2s 12ms/step - loss: 0.1824 - accuracy: 0.9444\n",
            "Epoch 82/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 0.1834 - accuracy: 0.9412\n",
            "Epoch 83/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 0.2038 - accuracy: 0.9370\n",
            "Epoch 84/100\n",
            "162/162 [==============================] - 2s 12ms/step - loss: 0.1675 - accuracy: 0.9457\n",
            "Epoch 85/100\n",
            "162/162 [==============================] - 2s 13ms/step - loss: 0.2012 - accuracy: 0.9348\n",
            "Epoch 86/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 0.1861 - accuracy: 0.9436\n",
            "Epoch 87/100\n",
            "162/162 [==============================] - 2s 12ms/step - loss: 0.1565 - accuracy: 0.9461\n",
            "Epoch 88/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 0.1788 - accuracy: 0.9467\n",
            "Epoch 89/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 0.2081 - accuracy: 0.9383\n",
            "Epoch 90/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 0.1973 - accuracy: 0.9383\n",
            "Epoch 91/100\n",
            "162/162 [==============================] - 2s 12ms/step - loss: 0.2039 - accuracy: 0.9362\n",
            "Epoch 92/100\n",
            "162/162 [==============================] - 2s 12ms/step - loss: 0.1680 - accuracy: 0.9475\n",
            "Epoch 93/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 0.2035 - accuracy: 0.9370\n",
            "Epoch 94/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 0.1702 - accuracy: 0.9442\n",
            "Epoch 95/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 0.2020 - accuracy: 0.9377\n",
            "Epoch 96/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 0.1779 - accuracy: 0.9461\n",
            "Epoch 97/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 0.1679 - accuracy: 0.9477\n",
            "Epoch 98/100\n",
            "162/162 [==============================] - 2s 12ms/step - loss: 0.1589 - accuracy: 0.9516\n",
            "Epoch 99/100\n",
            "162/162 [==============================] - 2s 12ms/step - loss: 0.1374 - accuracy: 0.9605\n",
            "Epoch 100/100\n",
            "162/162 [==============================] - 2s 11ms/step - loss: 0.1341 - accuracy: 0.9599\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc0a78aba90>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "score = cnn4.evaluate(x_test, y_test, verbose=1)\n",
        "print('\\n', 'Test accuracy:', score[1])"
      ],
      "metadata": {
        "id": "DB5COMKoxCnP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9d592d3-7c5e-4e95-d78a-e1746b3455b0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17/17 [==============================] - 1s 13ms/step - loss: 3.6054 - accuracy: 0.4296\n",
            "\n",
            " Test accuracy: 0.4296296238899231\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn4.save('cnn4.h5')"
      ],
      "metadata": {
        "id": "1BEMtgNNCe61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_array(img):\n",
        "    im = cv2.imread(img)\n",
        "    img = Image.fromarray(im, 'RGB')\n",
        "    image = img.resize((50, 50))\n",
        "    return np.array(image)\n",
        "def get_animal_name(label):\n",
        "    return categories[label]\n",
        "def predict_animal(file):\n",
        "    print(\"Predicting .................................\")\n",
        "    ar=convert_to_array(file)\n",
        "    ar=ar/255\n",
        "    label=1\n",
        "    a=[]\n",
        "    a.append(ar)\n",
        "    a=np.array(a)\n",
        "    score=cnn4.predict(a,verbose=1)\n",
        "    label_index=np.argmax(score)\n",
        "    acc=np.max(score)\n",
        "    animal=get_animal_name(label_index)\n",
        "    print(\"The predicted Animal is a \"+animal+\" with accuracy =    \"+str(acc))"
      ],
      "metadata": {
        "id": "RCKsT8QvNUqq"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_animal('download (8).jpeg')"
      ],
      "metadata": {
        "id": "MEFMedNdEUj6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1baa8d4a-7b00-4ac1-95d3-d43f47be2308"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting .................................\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "The predicted Animal is a kangaroo with accuracy =    0.17730708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YzjyUsZKQ57K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}